# AYA Master Implementation Plan
**Generated:** October 6, 2025 00:10:02  
**System:** ALPHA.local (macOS)  
**User:** arthurdell  
**Project:** Unified Knowledge Base Deployment Across Three-System Architecture

---

## Executive Summary

This document outlines the complete implementation plan for deploying a unified knowledge base infrastructure across three Mac systems (ALPHA, BETA, AIR) using PostgreSQL 16 with pgvector extension. The architecture provides zero data loss, sub-60-second failover capability, and offline operation support through a combination of streaming replication, GPU-accelerated embeddings, and intelligent synchronization.

---

## Recent Work Completed: PostgreSQL 18 Consolidation (October 5-6, 2025)

### Problem Identified
ALPHA system was running dual PostgreSQL installations (version 16 and 18) simultaneously, creating:
- Port conflicts and resource waste
- Configuration confusion
- Potential for connection errors
- Legacy bloat in system directories

### Actions Executed
1. **Audited Installation State**
   - Discovered PostgreSQL 16.10 running on port 5432
   - Discovered PostgreSQL 18.0 running on port 5433
   - Both auto-starting via LaunchDaemons
   - 16 background processes for PG 16, 7 for PG 18

2. **Executed Clean Migration**
   - Stopped PostgreSQL 16 master process (PID 531)
   - Unloaded PostgreSQL 16 LaunchDaemon
   - Removed `/Library/LaunchDaemons/postgresql-16.plist`
   - Deleted entire PostgreSQL 16 installation (`/Library/PostgreSQL/16`)
   - Verified PostgreSQL 18 claimed default port 5432

3. **Verified Final State**
   - PostgreSQL 18.0 operational on port 5432
   - Socket file created at `/tmp/.s.PGSQL.5432`
   - Connection testing successful
   - PATH configured for direct psql access
   - Single LaunchDaemon entry remaining

### Current PostgreSQL Configuration (ALPHA)
- **Version:** PostgreSQL 18.0 (x86_64-apple-darwin23.6.0, 64-bit)
- **Port:** 5432 (TCP/IPv4 and IPv6)
- **Installation Root:** `/Library/PostgreSQL/18`
- **Data Directory:** `/Library/PostgreSQL/18/data`
- **Auto-Start:** Enabled via LaunchDaemon
- **Status:** Production-ready, single clean installation

### Key Outcomes
- Zero data loss (no active databases existed)
- Eliminated resource contention
- Simplified configuration management
- Established baseline for cluster deployment
- Documented complete system state

---

## System Inventory

### AIR (MacBook Air M4)
- **Hardware:** 32GB RAM, 10 GPU cores, 494GB SSD
- **OS:** macOS 26.0.1
- **Network:** 
  - Tailscale: 100.103.127.52
  - WiFi: 192.168.1.242
- **Role:** Mobile client with local cache
- **Status:** Frequently offline, requires sync capability

### ALPHA (Mac Studio M3 Ultra)
- **Hardware:** 512GB RAM, 80 GPU cores, 16TB+4TB storage
- **OS:** macOS 26.0.1
- **Network:**
  - Tailscale: 100.106.113.76
  - Ethernet: 192.168.0.80
- **Role:** Primary database server
- **Status:** Always-on, currently running PostgreSQL 18.0

### BETA (Mac Studio M3 Ultra)
- **Hardware:** 256GB RAM, 80 GPU cores, 994GB+16TB storage
- **OS:** macOS 26.0.1
- **Network:**
  - Tailscale: 100.89.227.75
  - Ethernet: 192.168.0.20
- **Role:** Hot-standby replica server
- **Status:** Always-on, awaiting PostgreSQL installation

### Network Performance Characteristics
- **ALPHA ↔ BETA:** 1.4ms latency via 2.5GbE direct connection
- **AIR ↔ ALPHA/BETA:** 13.8ms latency via Tailscale DERP relay (Dubai)
- **SSH Connectivity:** Bidirectional ED25519 keys established across all systems

---

## Architectural Overview

### Core Components

1. **PostgreSQL 16 with pgvector Extension**
   - Vector storage for 768-dimensional embeddings
   - Cosine similarity search capability
   - IVFFlat indexing for performance

2. **Streaming Replication (ALPHA → BETA)**
   - Sub-100ms synchronization over 2.5GbE
   - Synchronous commit for zero data loss
   - Automatic WAL streaming

3. **Pull-Based Sync Daemon (AIR ← ALPHA)**
   - Periodic full sync every 5 minutes
   - Real-time change notifications via LISTEN/NOTIFY
   - Write queue for offline operations

4. **MLX Metal-Accelerated Embedding Services**
   - GPU-optimized vector generation on all nodes
   - ALPHA: 80 cores, BETA: 80 cores, AIR: 10 cores
   - FastAPI HTTP interface on port 8765

5. **MCP Servers for IDE Integration**
   - JSON-RPC 2.0 protocol over stdin/stdout
   - Query and add operations
   - Local PostgreSQL connections

6. **LISTEN/NOTIFY for Real-Time Propagation**
   - Change notifications broadcast from ALPHA
   - Sub-second propagation across cluster
   - Triggers immediate sync on AIR when online

7. **Write Queue System for Offline Operations**
   - AIR queues writes when disconnected
   - Automatic push on reconnection
   - Guarantees eventual consistency

8. **Automatic Failover with pg_ctl promote**
   - BETA promotion to primary on ALPHA failure
   - Sub-60-second failover time
   - Manual recovery procedures documented

9. **WAL Archiving for Point-in-Time Recovery**
   - Continuous archive to `/var/lib/postgresql/wal_archive/`
   - Recovery from any point in time
   - Protection against data corruption

10. **Local Caching Layer**
    - AIR maintains full local copy
    - Offline query capability
    - Sync on reconnection

---

## Database Schema Design

### Database: aya_rag
**Owner:** aya_user  
**Extensions:** pgvector

### Table: documents
```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    category VARCHAR(50) DEFAULT 'general',
    source VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**Purpose:** Store complete document content with metadata  
**Indexes:**
- `idx_documents_category` on category
- `idx_documents_created_at` on created_at DESC

### Table: chunks
```sql
CREATE TABLE chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    chunk_text TEXT NOT NULL,
    embedding vector(768),
    chunk_index INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW()
);
```

**Purpose:** Store document chunks with vector embeddings  
**Indexes:**
- `idx_chunks_embedding` using ivfflat (embedding vector_cosine_ops) WITH (lists = 100)
- `idx_chunks_document_id` on document_id

### Table: write_queue (AIR only)
```sql
CREATE TABLE write_queue (
    id SERIAL PRIMARY KEY,
    operation VARCHAR(10),
    table_name VARCHAR(50),
    data JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    synced BOOLEAN DEFAULT FALSE
);
```

**Purpose:** Queue writes when AIR is offline  
**Behavior:** Auto-sync on reconnection, mark synced=TRUE, periodic cleanup

---

## Implementation Plan: Step-by-Step

### Phase 1: ALPHA Primary Database Setup (Estimated: 60 minutes)

#### Step 1.1: Install PostgreSQL 16
**NOTE:** ALPHA currently has PostgreSQL 18 installed. Decision required: Downgrade to 16 for compatibility with planned architecture, or update architecture to use PostgreSQL 18.

**If downgrading to PostgreSQL 16:**
```bash
# Stop PostgreSQL 18
brew services stop postgresql@18

# Install PostgreSQL 16
brew install postgresql@16

# Initialize new cluster
initdb -D /usr/local/var/postgres-16
```

**If proceeding with PostgreSQL 18:**
Update all references in architecture from PostgreSQL 16 to PostgreSQL 18. Verify pgvector compatibility with PostgreSQL 18.

**Action Required:** Decide on PostgreSQL version before proceeding.

#### Step 1.2: Start PostgreSQL Service
```bash
brew services start postgresql@16
# or
brew services start postgresql@18
```

**Verification:**
```bash
psql -U postgres -c "SELECT version();"
ps aux | grep postgres | grep -v grep
netstat -an | grep LISTEN | grep 5432
```

**Expected Result:** PostgreSQL running on port 5432, accepting connections

#### Step 1.3: Create Database and User
```bash
psql -U postgres
```

```sql
CREATE DATABASE aya_rag;
CREATE USER aya_user WITH PASSWORD 'secure_password_here';
GRANT ALL PRIVILEGES ON DATABASE aya_rag TO aya_user;
\q
```

**Verification:**
```bash
psql -U aya_user -d aya_rag -c "SELECT current_database(), current_user;"
```

**Expected Result:** aya_rag database accessible by aya_user

#### Step 1.4: Install and Enable pgvector Extension
```bash
# Install pgvector
brew install pgvector

# Enable in database
psql -U postgres -d aya_rag
```

```sql
CREATE EXTENSION vector;
\dx
```

**Verification:**
```sql
SELECT * FROM pg_extension WHERE extname = 'vector';
```

**Expected Result:** pgvector extension installed and active

#### Step 1.5: Create Database Schema
```bash
psql -U aya_user -d aya_rag
```

```sql
-- Create documents table
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    category VARCHAR(50) DEFAULT 'general',
    source VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Create chunks table
CREATE TABLE chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    chunk_text TEXT NOT NULL,
    embedding vector(768),
    chunk_index INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW()
);

-- Create indexes
CREATE INDEX idx_chunks_embedding ON chunks 
    USING ivfflat (embedding vector_cosine_ops) 
    WITH (lists = 100);

CREATE INDEX idx_chunks_document_id ON chunks(document_id);
CREATE INDEX idx_documents_category ON documents(category);
CREATE INDEX idx_documents_created_at ON documents(created_at DESC);

-- Verify schema
\dt
\d documents
\d chunks
```

**Verification:**
```sql
SELECT count(*) FROM information_schema.tables 
WHERE table_schema = 'public' 
AND table_name IN ('documents', 'chunks');
```

**Expected Result:** Returns 2 (both tables created)

#### Step 1.6: Configure Replication Settings
```bash
# Edit postgresql.conf
nano /usr/local/var/postgres/postgresql.conf
# or for PostgreSQL 16
nano /usr/local/var/postgres-16/postgresql.conf
```

**Add/modify the following settings:**
```
wal_level = replica
max_wal_senders = 3
max_replication_slots = 3
synchronous_commit = on
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'
listen_addresses = '*'
port = 5432
```

**Create WAL archive directory:**
```bash
sudo mkdir -p /var/lib/postgresql/wal_archive
sudo chown postgres:postgres /var/lib/postgresql/wal_archive
sudo chmod 700 /var/lib/postgresql/wal_archive
```

#### Step 1.7: Configure Client Authentication
```bash
# Edit pg_hba.conf
nano /usr/local/var/postgres/pg_hba.conf
```

**Add the following line (before other entries):**
```
# Allow BETA replication from 192.168.0.20
host    replication    aya_user    192.168.0.20/32    md5

# Allow Tailscale connections from AIR
host    aya_rag        aya_user    100.103.127.52/32  md5

# Allow local connections
host    aya_rag        aya_user    127.0.0.1/32       md5
```

**Verification:**
```bash
cat /usr/local/var/postgres/pg_hba.conf | grep -E "replication|aya_rag"
```

**Expected Result:** Three entries visible for replication and database access

#### Step 1.8: Create Replication Slot for BETA
```bash
psql -U postgres -d aya_rag
```

```sql
SELECT pg_create_physical_replication_slot('beta_slot');
SELECT slot_name, slot_type, active FROM pg_replication_slots;
```

**Expected Result:** beta_slot created, type=physical, active=f

#### Step 1.9: Restart PostgreSQL with New Configuration
```bash
brew services restart postgresql@16
# or
brew services restart postgresql@18

# Wait 5 seconds for restart
sleep 5

# Verify service running
brew services list | grep postgresql
ps aux | grep postgres | grep -v grep
```

**Expected Result:** PostgreSQL running with new configuration

#### Step 1.10: Test Vector Operations
```bash
psql -U aya_user -d aya_rag
```

```sql
-- Insert test document
INSERT INTO documents (content, category) 
VALUES ('Test document content', 'test') 
RETURNING id;

-- Insert test chunk with vector (use returned document id)
INSERT INTO chunks (document_id, chunk_text, embedding) 
VALUES (
    1, 
    'Test chunk content',
    array_fill(0.1, ARRAY[768])::real[]::vector
);

-- Test vector similarity search
SELECT id, chunk_text, 
       embedding <=> array_fill(0.1, ARRAY[768])::real[]::vector AS distance
FROM chunks
ORDER BY embedding <=> array_fill(0.1, ARRAY[768])::real[]::vector
LIMIT 5;

-- Cleanup test data
DELETE FROM documents WHERE category = 'test';
```

**Expected Result:** Vector operations succeed, similarity search returns results

#### Step 1.11: Install MLX and Dependencies
```bash
# Install Python packages
pip3 install mlx sentence-transformers fastapi uvicorn pydantic psycopg2-binary pgvector
```

**Verification:**
```bash
python3 -c "import mlx; import sentence_transformers; print('MLX and dependencies installed')"
```

**Expected Result:** No import errors, confirmation message printed

#### Step 1.12: Create Embedding Service
```bash
# Create service directory
mkdir -p ~/aya_rag/services
cd ~/aya_rag/services

# Create embedding service file
nano embedding_service.py
```

**File content: embedding_service.py**
```python
import hashlib
from fastapi import FastAPI
from pydantic import BaseModel
import mlx.core as mx
from sentence_transformers import SentenceTransformer
import numpy as np

app = FastAPI()

# Global cache and model
cache_dict = {}
model = None

class EmbedRequest(BaseModel):
    text: str

@app.on_event("startup")
async def load_model():
    global model
    # Load model with MLX Metal acceleration
    model = SentenceTransformer('BAAI/bge-base-en-v1.5')
    print(f"Model loaded. MLX Metal available: {mx.metal.is_available()}")

@app.get("/health")
async def health():
    return {"status": "healthy", "metal_available": mx.metal.is_available()}

@app.post("/embed")
async def embed(request: EmbedRequest):
    # Generate hash for cache lookup
    text_hash = hashlib.md5(request.text.encode()).hexdigest()
    
    # Check cache
    if text_hash in cache_dict:
        return {"embedding": cache_dict[text_hash], "cached": True}
    
    # Generate embedding
    embedding = model.encode([request.text], normalize_embeddings=True)
    vector = embedding[0].tolist()
    
    # Cache result
    cache_dict[text_hash] = vector
    
    return {"embedding": vector, "cached": False}

@app.get("/stats")
async def stats():
    return {
        "cache_size": len(cache_dict),
        "metal_active_memory": mx.metal.get_active_memory() if mx.metal.is_available() else 0
    }
```

Save and exit (Ctrl+X, Y, Enter)

#### Step 1.13: Start Embedding Service
```bash
cd ~/aya_rag/services

# Start service in background
nohup uvicorn embedding_service:app --host 0.0.0.0 --port 8765 > embedding.log 2>&1 &

# Get process ID
echo $! > embedding_service.pid

# Wait for startup
sleep 10

# Verify service running
curl http://localhost:8765/health
```

**Expected Result:**
```json
{"status": "healthy", "metal_available": true}
```

#### Step 1.14: Test Embedding Service
```bash
# Test embedding generation
curl -X POST http://localhost:8765/embed \
  -H "Content-Type: application/json" \
  -d '{"text": "This is a test sentence for embedding"}' | python3 -m json.tool

# Verify response contains 768-dimensional vector
curl -X POST http://localhost:8765/embed \
  -H "Content-Type: application/json" \
  -d '{"text": "This is a test sentence for embedding"}' | python3 -c "import sys, json; data=json.load(sys.stdin); print(f'Vector length: {len(data[\"embedding\"])}, Cached: {data[\"cached\"]}')"
```

**Expected Result:**
- First call: Vector length: 768, Cached: False
- Second call (same text): Vector length: 768, Cached: True

#### Step 1.15: Phase 1 Verification Checklist
```bash
# 1. PostgreSQL running
ps aux | grep postgres | grep -v grep | wc -l
# Expected: >5 (multiple postgres processes)

# 2. Database exists
psql -U postgres -l | grep aya_rag
# Expected: aya_rag database listed

# 3. pgvector enabled
psql -U aya_user -d aya_rag -c "SELECT * FROM pg_extension WHERE extname='vector';"
# Expected: 1 row returned

# 4. Tables created
psql -U aya_user -d aya_rag -c "\dt"
# Expected: documents and chunks tables listed

# 5. Indexes created
psql -U aya_user -d aya_rag -c "\di"
# Expected: 4 indexes listed

# 6. Replication configured
psql -U postgres -c "SHOW wal_level;"
# Expected: replica

# 7. Replication slot exists
psql -U postgres -c "SELECT slot_name FROM pg_replication_slots;"
# Expected: beta_slot listed

# 8. Embedding service running
curl -s http://localhost:8765/health | grep healthy
# Expected: status: healthy

# 9. WAL archive directory exists
ls -ld /var/lib/postgresql/wal_archive
# Expected: Directory exists with postgres ownership

# 10. Port listening
netstat -an | grep LISTEN | grep 5432
# Expected: tcp4 and tcp6 on *.5432

# All checks passed: Phase 1 complete
```

**Phase 1 Status:** ALPHA primary database fully configured and operational

---

### Phase 2: BETA Replica Setup (Estimated: 45 minutes)

**Prerequisites:** Phase 1 completed successfully on ALPHA

#### Step 2.1: Install PostgreSQL on BETA
```bash
# SSH to BETA
ssh arthurdell@192.168.0.20

# Install PostgreSQL (match ALPHA version)
brew install postgresql@16
# or
brew install postgresql@18
```

**Verification:**
```bash
which psql
psql --version
```

**Expected Result:** PostgreSQL binary available, version matches ALPHA

#### Step 2.2: Stop Default PostgreSQL Service
```bash
# Stop if auto-started
brew services stop postgresql@16

# Verify stopped
ps aux | grep postgres | grep -v grep
# Expected: No postgres processes
```

#### Step 2.3: Remove Default Data Directory
```bash
# Remove default initialized data
rm -rf /usr/local/var/postgres

# Verify removal
ls /usr/local/var/ | grep postgres
# Expected: No postgres directory
```

#### Step 2.4: Create Base Backup from ALPHA
```bash
# Create .pgpass file for password-less connection
echo "192.168.0.80:5432:*:aya_user:secure_password_here" > ~/.pgpass
chmod 600 ~/.pgpass

# Create base backup from ALPHA
pg_basebackup \
  -h 192.168.0.80 \
  -U aya_user \
  -D /usr/local/var/postgres \
  -P \
  -R \
  --slot=beta_slot

# This will take several minutes for initial sync
```

**Expected Output:**
```
[timestamp]/[size] kB (100%), 1/1 tablespace
```

**Verification:**
```bash
# Check data directory created
ls -la /usr/local/var/postgres

# Check standby.signal file exists
ls /usr/local/var/postgres/standby.signal

# Check recovery configuration
cat /usr/local/var/postgres/postgresql.auto.conf | grep primary_conninfo
```

**Expected Result:** Data directory populated, standby configuration present

#### Step 2.5: Start BETA PostgreSQL
```bash
brew services start postgresql@16

# Wait for startup
sleep 5

# Verify running
ps aux | grep postgres | grep -v grep
```

**Expected Result:** Multiple postgres processes running

#### Step 2.6: Verify Replication Status on BETA
```bash
# Connect to BETA database
psql -U aya_user -d aya_rag

# Check recovery mode (should be true)
SELECT pg_is_in_recovery();
-- Expected: t (true)

# Check replication lag
SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;
-- Expected: <1 second

# List databases
\l

# List tables
\dt

# Check chunk count
SELECT COUNT(*) FROM chunks;

# Exit
\q
```

**Expected Results:**
- Recovery mode: true
- Lag: <1 second
- All databases and tables present
- Data synchronized from ALPHA

#### Step 2.7: Verify Replication Status on ALPHA
```bash
# SSH back to ALPHA or open new terminal
ssh arthurdell@192.168.0.80

# Check replication status
psql -U postgres -c "SELECT * FROM pg_stat_replication;"
```

**Expected Output:**
```
 pid  | usename  | application_name | client_addr   | state     | sync_state
------+----------+------------------+---------------+-----------+-----------
 XXXX | aya_user | beta             | 192.168.0.20  | streaming | sync
```

**Verification Points:**
- client_addr: 192.168.0.20 (BETA)
- state: streaming
- sync_state: sync (for synchronous replication)

#### Step 2.8: Test Read-Only Nature of BETA
```bash
# On BETA, attempt write operation
psql -U aya_user -d aya_rag -c "INSERT INTO documents (content) VALUES ('test');"
```

**Expected Result:** Error message
```
ERROR: cannot execute INSERT in a read-only transaction
```

This confirms BETA is properly configured as read-only replica.

#### Step 2.9: Install MLX and Dependencies on BETA
```bash
# Install Python packages
pip3 install mlx sentence-transformers fastapi uvicorn pydantic psycopg2-binary pgvector

# Verify installation
python3 -c "import mlx; import sentence_transformers; print('Dependencies installed')"
```

#### Step 2.10: Deploy Embedding Service on BETA
```bash
# Create service directory
mkdir -p ~/aya_rag/services
cd ~/aya_rag/services

# Copy embedding service from ALPHA
scp arthurdell@192.168.0.80:~/aya_rag/services/embedding_service.py .

# Start service
nohup uvicorn embedding_service:app --host 0.0.0.0 --port 8765 > embedding.log 2>&1 &
echo $! > embedding_service.pid

# Wait for startup
sleep 10

# Test service
curl http://localhost:8765/health
```

**Expected Result:**
```json
{"status": "healthy", "metal_available": true}
```

#### Step 2.11: Test Replication Lag Under Load
```bash
# On ALPHA, insert test data rapidly
psql -U aya_user -d aya_rag

INSERT INTO documents (content, category) 
SELECT 'Test document ' || generate_series(1, 100), 'test';

\q

# On BETA, check lag immediately
psql -U aya_user -d aya_rag -c "SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;"

# Check data arrived
psql -U aya_user -d aya_rag -c "SELECT COUNT(*) FROM documents WHERE category='test';"
```

**Expected Results:**
- Lag: <1 second even during bulk insert
- Count matches ALPHA (100 documents)

#### Step 2.12: Cleanup Test Data
```bash
# On ALPHA (only writable system)
psql -U aya_user -d aya_rag -c "DELETE FROM documents WHERE category='test';"

# Verify cleanup replicated to BETA
ssh arthurdell@192.168.0.20
psql -U aya_user -d aya_rag -c "SELECT COUNT(*) FROM documents WHERE category='test';"
# Expected: 0
```

#### Step 2.13: Phase 2 Verification Checklist
```bash
# On BETA:

# 1. PostgreSQL running in recovery mode
psql -U aya_user -d aya_rag -c "SELECT pg_is_in_recovery();"
# Expected: t

# 2. Replication lag acceptable
psql -U aya_user -d aya_rag -c "SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;"
# Expected: <1 second

# 3. Cannot write
psql -U aya_user -d aya_rag -c "INSERT INTO documents (content) VALUES ('test');" 2>&1 | grep "read-only"
# Expected: Error message present

# 4. Embedding service running
curl -s http://localhost:8765/health | grep healthy
# Expected: healthy status

# On ALPHA:

# 5. Replication connection active
psql -U postgres -c "SELECT application_name, state FROM pg_stat_replication;"
# Expected: beta, streaming

# 6. Replication slot in use
psql -U postgres -c "SELECT slot_name, active FROM pg_replication_slots;"
# Expected: beta_slot, t

# All checks passed: Phase 2 complete
```

**Phase 2 Status:** BETA replica fully synchronized with ALPHA, replication operational

---

### Phase 3: AIR Client Setup (Estimated: 30 minutes)

**Prerequisites:** Phase 1 and 2 completed successfully

#### Step 3.1: Install PostgreSQL on AIR
```bash
# Install PostgreSQL (match ALPHA/BETA version)
brew install postgresql@16

# Initialize local cluster
initdb -D /usr/local/var/postgres

# Start service
brew services start postgresql@16
```

**Verification:**
```bash
ps aux | grep postgres | grep -v grep
psql -U postgres -c "SELECT version();"
```

**Expected Result:** Local PostgreSQL running

#### Step 3.2: Create Local Database and Schema
```bash
psql -U postgres
```

```sql
CREATE DATABASE aya_rag;
CREATE USER aya_user WITH PASSWORD 'local_password_here';
GRANT ALL PRIVILEGES ON DATABASE aya_rag TO aya_user;
\q
```

```bash
# Enable pgvector
psql -U postgres -d aya_rag -c "CREATE EXTENSION vector;"

# Create schema (documents and chunks tables)
psql -U aya_user -d aya_rag
```

```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    category VARCHAR(50) DEFAULT 'general',
    source VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    chunk_text TEXT NOT NULL,
    embedding vector(768),
    chunk_index INTEGER DEFAULT 0,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_chunks_embedding ON chunks 
    USING ivfflat (embedding vector_cosine_ops) 
    WITH (lists = 100);
CREATE INDEX idx_chunks_document_id ON chunks(document_id);
CREATE INDEX idx_documents_category ON documents(category);
CREATE INDEX idx_documents_created_at ON documents(created_at DESC);

\q
```

#### Step 3.3: Create Write Queue Table
```bash
psql -U aya_user -d aya_rag
```

```sql
CREATE TABLE write_queue (
    id SERIAL PRIMARY KEY,
    operation VARCHAR(10),
    table_name VARCHAR(50),
    data JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    synced BOOLEAN DEFAULT FALSE
);

CREATE INDEX idx_write_queue_synced ON write_queue(synced) WHERE synced = FALSE;

\dt
\q
```

**Expected Result:** All three tables created (documents, chunks, write_queue)

#### Step 3.4: Test Tailscale Connectivity to ALPHA
```bash
# Verify Tailscale running
tailscale status | grep ALPHA
# Expected: 100.106.113.76 ALPHA

# Test connectivity
ping -c 3 100.106.113.76

# Test PostgreSQL port
nc -zv 100.106.113.76 5432
# Expected: Connection succeeded
```

**Expected Result:** Tailscale active, ALPHA reachable on port 5432

#### Step 3.5: Configure ALPHA to Accept AIR Connections
```bash
# SSH to ALPHA
ssh arthurdell@192.168.0.80

# Edit pg_hba.conf (already done in Step 1.7, verify)
grep "100.103.127.52" /usr/local/var/postgres/pg_hba.conf
```

**Expected Result:** Entry exists allowing AIR Tailscale IP

#### Step 3.6: Test Remote Connection from AIR to ALPHA
```bash
# On AIR, create .pgpass for ALPHA connection
echo "100.106.113.76:5432:aya_rag:aya_user:secure_password_here" >> ~/.pgpass
chmod 600 ~/.pgpass

# Test connection
psql -h 100.106.113.76 -U aya_user -d aya_rag -c "SELECT COUNT(*) FROM documents;"
```

**Expected Result:** Connection succeeds, returns document count from ALPHA

#### Step 3.7: Install Dependencies on AIR
```bash
pip3 install psycopg2-binary pgvector mlx sentence-transformers fastapi uvicorn asyncio aiohttp
```

**Verification:**
```bash
python3 -c "import psycopg2, pgvector, mlx, asyncio, aiohttp; print('All dependencies installed')"
```

#### Step 3.8: Deploy Embedding Service on AIR
```bash
mkdir -p ~/aya_rag/services
cd ~/aya_rag/services

# Copy from ALPHA or create manually
scp arthurdell@192.168.0.80:~/aya_rag/services/embedding_service.py .

# Start service
nohup uvicorn embedding_service:app --host 0.0.0.0 --port 8765 > embedding.log 2>&1 &
echo $! > embedding_service.pid

sleep 10

# Test
curl http://localhost:8765/health
```

**Expected Result:** Embedding service operational on AIR

#### Step 3.9: Create AIR Sync Daemon
```bash
cd ~/aya_rag/services
nano air_sync_daemon.py
```

**File content: air_sync_daemon.py**
```python
import asyncio
import psycopg2
from pgvector.psycopg2 import register_vector
import json
import time
import sys
from datetime import datetime

class AirSyncDaemon:
    def __init__(self, alpha_host, local_host):
        self.alpha_host = alpha_host
        self.local_host = local_host
        self.alpha_conn = None
        self.local_conn = None
        self.online = False

    
    def connect_alpha(self):
        try:
            self.alpha_conn = psycopg2.connect(
                host=self.alpha_host,
                port=5432,
                database='aya_rag',
                user='aya_user',
                password='secure_password_here'
            )
            register_vector(self.alpha_conn)
            self.online = True
            print(f"[{datetime.now()}] Connected to ALPHA")
            return True
        except Exception as e:
            self.online = False
            print(f"[{datetime.now()}] Failed to connect to ALPHA: {e}")
            return False
    
    def connect_local(self):
        try:
            self.local_conn = psycopg2.connect(
                host=self.local_host,
                port=5432,
                database='aya_rag',
                user='aya_user',
                password='local_password_here'
            )
            register_vector(self.local_conn)
            print(f"[{datetime.now()}] Connected to local database")
            return True
        except Exception as e:
            print(f"[{datetime.now()}] Failed to connect to local: {e}")
            return False
    
    def pull_updates(self):
        if not self.online:
            return
        
        try:
            alpha_cur = self.alpha_conn.cursor()
            local_cur = self.local_conn.cursor()
            
            # Get max ID from local
            local_cur.execute("SELECT COALESCE(MAX(id), 0) FROM documents")
            max_local_id = local_cur.fetchone()[0]
            
            # Pull new documents from ALPHA
            alpha_cur.execute(
                "SELECT id, content, metadata, category, source, created_at, updated_at "
                "FROM documents WHERE id > %s ORDER BY id",
                (max_local_id,)
            )

            
            documents = alpha_cur.fetchall()
            
            if documents:
                print(f"[{datetime.now()}] Pulling {len(documents)} new documents")
                
                for doc in documents:
                    # Insert document
                    local_cur.execute(
                        "INSERT INTO documents (id, content, metadata, category, source, created_at, updated_at) "
                        "VALUES (%s, %s, %s, %s, %s, %s, %s) "
                        "ON CONFLICT (id) DO UPDATE SET "
                        "content = EXCLUDED.content, metadata = EXCLUDED.metadata",
                        doc
                    )
                    
                    # Pull chunks for this document
                    alpha_cur.execute(
                        "SELECT id, document_id, chunk_text, embedding, chunk_index, metadata, created_at "
                        "FROM chunks WHERE document_id = %s",
                        (doc[0],)
                    )
                    chunks = alpha_cur.fetchall()
                    
                    for chunk in chunks:
                        local_cur.execute(
                            "INSERT INTO chunks (id, document_id, chunk_text, embedding, chunk_index, metadata, created_at) "
                            "VALUES (%s, %s, %s, %s, %s, %s, %s) "
                            "ON CONFLICT (id) DO UPDATE SET "
                            "chunk_text = EXCLUDED.chunk_text, embedding = EXCLUDED.embedding",
                            chunk
                        )
                
                self.local_conn.commit()
                print(f"[{datetime.now()}] Sync complete: {len(documents)} documents")
            
            alpha_cur.close()
            local_cur.close()
            
        except Exception as e:
            print(f"[{datetime.now()}] Error during pull: {e}")
            self.local_conn.rollback()
    
    def push_queued_writes(self):
        if not self.online:
            return

        
        try:
            local_cur = self.local_conn.cursor()
            alpha_cur = self.alpha_conn.cursor()
            
            # Get unsynced writes
            local_cur.execute(
                "SELECT id, operation, table_name, data FROM write_queue WHERE synced = FALSE ORDER BY id"
            )
            queued = local_cur.fetchall()
            
            if queued:
                print(f"[{datetime.now()}] Pushing {len(queued)} queued writes")
                
                for queue_item in queued:
                    queue_id, operation, table_name, data = queue_item
                    
                    if operation == 'INSERT' and table_name == 'documents':
                        # Execute on ALPHA
                        alpha_cur.execute(
                            "INSERT INTO documents (content, metadata, category, source) "
                            "VALUES (%s, %s, %s, %s) RETURNING id",
                            (data['content'], data.get('metadata', {}), 
                             data.get('category', 'general'), data.get('source'))
                        )
                        new_id = alpha_cur.fetchone()[0]
                        self.alpha_conn.commit()
                        
                        # Mark as synced
                        local_cur.execute(
                            "UPDATE write_queue SET synced = TRUE WHERE id = %s",
                            (queue_id,)
                        )
                        self.local_conn.commit()
                        
                        print(f"[{datetime.now()}] Synced write queue item {queue_id}, new ID: {new_id}")
                
            alpha_cur.close()
            local_cur.close()
            
        except Exception as e:
            print(f"[{datetime.now()}] Error during push: {e}")
            self.alpha_conn.rollback()
            self.local_conn.rollback()

    
    async def run(self):
        # Connect to local database
        if not self.connect_local():
            print("Failed to connect to local database. Exiting.")
            sys.exit(1)
        
        print(f"[{datetime.now()}] AIR Sync Daemon started")
        
        while True:
            # Attempt ALPHA connection
            if not self.online:
                self.connect_alpha()
            
            # If online, perform sync operations
            if self.online:
                try:
                    self.push_queued_writes()
                    self.pull_updates()
                except Exception as e:
                    print(f"[{datetime.now()}] Sync error: {e}")
                    self.online = False
                    if self.alpha_conn:
                        self.alpha_conn.close()
                        self.alpha_conn = None
            
            # Wait before next cycle
            await asyncio.sleep(60)  # 1 minute sync interval

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--alpha-host', default='100.106.113.76')
    parser.add_argument('--local-host', default='localhost')
    args = parser.parse_args()
    
    daemon = AirSyncDaemon(args.alpha_host, args.local_host)
    asyncio.run(daemon.run())
```

Save and exit

#### Step 3.10: Start Sync Daemon
```bash
cd ~/aya_rag/services

# Start daemon in background
nohup python3 air_sync_daemon.py --alpha-host 100.106.113.76 --local-host localhost > sync.log 2>&1 &
echo $! > sync_daemon.pid

# Monitor startup
tail -f sync.log
```

**Expected Output:**
```
[timestamp] Connected to local database
[timestamp] AIR Sync Daemon started
[timestamp] Connected to ALPHA
[timestamp] Pulling X new documents
```

Press Ctrl+C to stop tailing

#### Step 3.11: Test Offline Queueing
```bash
# Simulate offline by killing sync daemon temporarily
kill $(cat ~/aya_rag/services/sync_daemon.pid)

# Insert to write queue while "offline"
psql -U aya_user -d aya_rag
```

```sql
INSERT INTO write_queue (operation, table_name, data)
VALUES (
    'INSERT',
    'documents',
    '{"content": "Test offline write from AIR", "category": "test", "source": "air_offline_test"}'::jsonb
);

SELECT * FROM write_queue WHERE synced = FALSE;
\q
```

**Expected Result:** One row in write_queue with synced=FALSE

#### Step 3.12: Test Online Sync
```bash
# Restart sync daemon
nohup python3 ~/aya_rag/services/air_sync_daemon.py --alpha-host 100.106.113.76 > ~/aya_rag/services/sync.log 2>&1 &
echo $! > ~/aya_rag/services/sync_daemon.pid

# Wait for sync cycle
sleep 65

# Check if queued write was synced
psql -U aya_user -d aya_rag -c "SELECT synced FROM write_queue WHERE data->>'content' LIKE '%Test offline write%';"
# Expected: synced = t

# Verify on ALPHA
ssh arthurdell@192.168.0.80
psql -U aya_user -d aya_rag -c "SELECT content FROM documents WHERE content LIKE '%Test offline write%';"
# Expected: Document present
```

#### Step 3.13: Cleanup Test Data
```bash
# On ALPHA
psql -U aya_user -d aya_rag -c "DELETE FROM documents WHERE source = 'air_offline_test';"

# On AIR, wait for sync then check
sleep 65
psql -U aya_user -d aya_rag -c "SELECT COUNT(*) FROM documents WHERE source = 'air_offline_test';"
# Expected: 0
```

#### Step 3.14: Phase 3 Verification Checklist
```bash
# On AIR:

# 1. Local PostgreSQL running
ps aux | grep postgres | grep -v grep | wc -l
# Expected: >5

# 2. All tables created
psql -U aya_user -d aya_rag -c "\dt"
# Expected: documents, chunks, write_queue

# 3. Can connect to ALPHA
psql -h 100.106.113.76 -U aya_user -d aya_rag -c "SELECT 1;"
# Expected: Success

# 4. Embedding service running
curl -s http://localhost:8765/health | grep healthy
# Expected: healthy

# 5. Sync daemon running
ps aux | grep air_sync_daemon | grep -v grep
# Expected: Python process running

# 6. Sync log shows activity
tail -20 ~/aya_rag/services/sync.log | grep -E "Connected|Pulling|Pushing"
# Expected: Connection and sync messages

# 7. Data synchronized from ALPHA
psql -U aya_user -d aya_rag -c "SELECT COUNT(*) FROM documents;"
# Expected: Same count as ALPHA

# All checks passed: Phase 3 complete
```

**Phase 3 Status:** AIR client configured with local cache and sync daemon operational

---

### Phase 4: MCP Server Implementation (Estimated: 60 minutes)

**Prerequisites:** Phases 1, 2, and 3 completed successfully

#### Step 4.1: Create MCP Server Directory
```bash
# On ALPHA (will replicate to other systems)
mkdir -p ~/Agent/mcp_servers
cd ~/Agent/mcp_servers
```

#### Step 4.2: Create MCP Server Implementation
```bash
nano aya_postgres_mcp_server.py
```

**File content: aya_postgres_mcp_server.py (Part 1 - Imports and Setup)**
```python
#!/usr/bin/env python3
import sys
import json
import psycopg2
from pgvector.psycopg2 import register_vector
import requests
import os
from datetime import datetime

# Configuration from environment
DB_HOST = os.getenv('DB_HOST', 'localhost')
DB_NAME = os.getenv('DB_NAME', 'aya_rag')
DB_USER = os.getenv('DB_USER', 'aya_user')
DB_PASSWORD = os.getenv('DB_PASSWORD', '')
EMBEDDING_URL = os.getenv('EMBEDDING_URL', 'http://localhost:8765')
ALPHA_HOST = os.getenv('ALPHA_HOST', '')  # For AIR writes when online

class AyaMcpServer:
    def __init__(self):
        self.conn = None
        self.connect_db()
    
    def connect_db(self):
        try:
            self.conn = psycopg2.connect(
                host=DB_HOST,
                database=DB_NAME,
                user=DB_USER,
                password=DB_PASSWORD
            )
            register_vector(self.conn)
            self.log(f"Connected to database: {DB_HOST}:{DB_NAME}")
        except Exception as e:
            self.log(f"Database connection failed: {e}")
            self.conn = None
    
    def log(self, message):
        timestamp = datetime.now().isoformat()
        print(f"[{timestamp}] {message}", file=sys.stderr, flush=True)
    
    def get_embedding(self, text):
        try:
            response = requests.post(
                f"{EMBEDDING_URL}/embed",
                json={"text": text},
                timeout=10
            )
            response.raise_for_status()
            data = response.json()
            return data['embedding']
        except Exception as e:
            self.log(f"Embedding service error: {e}")
            return None
```

Continue to next section...

**Continue aya_postgres_mcp_server.py (Part 2 - Tool Handlers)**
```python
    
    def handle_query_aya_rag(self, params):
        query_text = params.get('query', '')
        limit = params.get('limit', 5)
        
        if not query_text:
            return {"error": "Query text required"}
        
        # Get query embedding
        query_vector = self.get_embedding(query_text)
        if not query_vector:
            return {"error": "Failed to generate embedding"}
        
        try:
            cur = self.conn.cursor()
            
            # Vector similarity search
            cur.execute("""
                SELECT 
                    c.id,
                    c.chunk_text,
                    c.embedding <=> %s::vector AS distance,
                    d.content,
                    d.metadata,
                    d.category,
                    d.source
                FROM chunks c
                JOIN documents d ON c.document_id = d.id
                ORDER BY c.embedding <=> %s::vector
                LIMIT %s
            """, (query_vector, query_vector, limit))
            
            results = []
            for row in cur.fetchall():
                results.append({
                    "chunk_id": row[0],
                    "chunk_text": row[1],
                    "distance": float(row[2]),
                    "document_content": row[3],
                    "metadata": row[4],
                    "category": row[5],
                    "source": row[6]
                })
            
            cur.close()
            
            self.log(f"Query '{query_text[:50]}...' returned {len(results)} results")
            return {"results": results, "count": len(results)}
            
        except Exception as e:
            self.log(f"Query error: {e}")
            return {"error": str(e)}
```

**Continue aya_postgres_mcp_server.py (Part 3 - Add Knowledge Handler)**
```python
    
    def handle_add_to_aya_rag(self, params):
        content = params.get('content', '')
        category = params.get('category', 'general')
        context = params.get('context', {})
        
        if not content:
            return {"error": "Content required"}
        
        try:
            # Generate embedding
            embedding = self.get_embedding(content)
            if not embedding:
                return {"error": "Failed to generate embedding"}
            
            cur = self.conn.cursor()
            
            # Insert document
            cur.execute("""
                INSERT INTO documents (content, metadata, category, source)
                VALUES (%s, %s, %s, %s)
                RETURNING id
            """, (content, json.dumps(context), category, 'mcp_server'))
            
            doc_id = cur.fetchone()[0]
            
            # Insert chunk with embedding
            cur.execute("""
                INSERT INTO chunks (document_id, chunk_text, embedding, metadata)
                VALUES (%s, %s, %s, %s)
                RETURNING id
            """, (doc_id, content, embedding, json.dumps(context)))
            
            chunk_id = cur.fetchone()[0]
            
            # Notify changes
            cur.execute("""
                NOTIFY aya_changes, %s
            """, (json.dumps({"action": "insert", "document_id": doc_id}),))
            
            self.conn.commit()
            cur.close()
            
            self.log(f"Added document {doc_id}, chunk {chunk_id}")
            return {
                "success": True,
                "document_id": doc_id,
                "chunk_id": chunk_id
            }
            
        except Exception as e:
            self.conn.rollback()
            self.log(f"Add error: {e}")
            return {"error": str(e)}
```

**Continue aya_postgres_mcp_server.py (Part 4 - JSON-RPC Protocol)**
```python
    
    def handle_initialize(self, request_id):
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "protocolVersion": "2024-11-05",
                "capabilities": {
                    "tools": {}
                },
                "serverInfo": {
                    "name": "aya-rag",
                    "version": "1.0.0"
                }
            }
        }
    
    def handle_tools_list(self, request_id):
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "tools": [
                    {
                        "name": "query_aya_rag",
                        "description": "Query unified AYA knowledge base with vector similarity search",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string",
                                    "description": "Search query text"
                                },
                                "limit": {
                                    "type": "number",
                                    "description": "Maximum number of results",
                                    "default": 5
                                }
                            },
                            "required": ["query"]
                        }
                    },
                    {
                        "name": "add_to_aya_rag",
                        "description": "Add knowledge to AYA database with automatic embedding",
                        "inputSchema": {
                            "type": "object",
                            "properties": {
                                "content": {
                                    "type": "string",
                                    "description": "Knowledge content to add"
                                },
                                "category": {
                                    "type": "string",
                                    "description": "Category classification",
                                    "default": "general"
                                },
                                "context": {
                                    "type": "object",
                                    "description": "Additional metadata context"
                                }
                            },
                            "required": ["content"]
                        }
                    }
                ]
            }
        }
```

**Continue aya_postgres_mcp_server.py (Part 5 - Main Loop)**
```python
    
    def handle_tools_call(self, request_id, tool_name, arguments):
        if tool_name == "query_aya_rag":
            result = self.handle_query_aya_rag(arguments)
        elif tool_name == "add_to_aya_rag":
            result = self.handle_add_to_aya_rag(arguments)
        else:
            result = {"error": f"Unknown tool: {tool_name}"}
        
        return {
            "jsonrpc": "2.0",
            "id": request_id,
            "result": {
                "content": [
                    {
                        "type": "text",
                        "text": json.dumps(result, indent=2)
                    }
                ]
            }
        }
    
    def handle_request(self, request):
        method = request.get('method', '')
        request_id = request.get('id')
        
        if method == 'initialize':
            return self.handle_initialize(request_id)
        elif method == 'tools/list':
            return self.handle_tools_list(request_id)
        elif method == 'tools/call':
            params = request.get('params', {})
            tool_name = params.get('name', '')
            arguments = params.get('arguments', {})
            return self.handle_tools_call(request_id, tool_name, arguments)
        elif method == 'notifications/initialized':
            # No response needed for notifications
            return None
        else:
            return {
                "jsonrpc": "2.0",
                "id": request_id,
                "error": {
                    "code": -32601,
                    "message": f"Method not found: {method}"
                }
            }
    
    def run(self):
        self.log("AYA MCP Server starting...")
        
        while True:
            try:
                line = sys.stdin.readline()
                if not line:
                    break
                
                request = json.loads(line)
                response = self.handle_request(request)
                
                if response:
                    print(json.dumps(response), flush=True)
                    
            except json.JSONDecodeError as e:
                self.log(f"JSON decode error: {e}")
            except Exception as e:
                self.log(f"Error: {e}")

if __name__ == "__main__":
    server = AyaMcpServer()
    server.run()
```

Save and exit (Ctrl+X, Y, Enter)

#### Step 4.3: Make Server Executable
```bash
chmod +x ~/Agent/mcp_servers/aya_postgres_mcp_server.py
```

#### Step 4.4: Test MCP Server Standalone
```bash
# Test with echo command
echo '{"jsonrpc":"2.0","id":1,"method":"initialize"}' | python3 ~/Agent/mcp_servers/aya_postgres_mcp_server.py
```

**Expected Output:** JSON response with protocolVersion, capabilities, serverInfo

#### Step 4.5: Deploy to All Systems
```bash
# Copy to BETA
scp ~/Agent/mcp_servers/aya_postgres_mcp_server.py arthurdell@192.168.0.20:~/Agent/mcp_servers/

# Copy to AIR
scp ~/Agent/mcp_servers/aya_postgres_mcp_server.py arthurdell@100.103.127.52:~/Agent/mcp_servers/
```

---

## Verification Protocol

### Critical Success Metrics

**Before claiming success, ALL of the following must be verified:**

1. **Component Health**
   - ALPHA: PostgreSQL running, embedding service active
   - BETA: PostgreSQL in recovery mode, embedding service active  
   - AIR: PostgreSQL running, embedding service active, sync daemon running

2. **Replication Status**
   - ALPHA → BETA streaming replication lag <100ms
   - Data consistency verified across ALPHA and BETA

3. **AIR Synchronization**
   - AIR successfully pulls updates from ALPHA
   - Write queue functions when offline
   - Queued writes push to ALPHA when online

4. **End-to-End Data Flow**
   - Insert on ALPHA appears on BETA within 1 second
   - Insert on ALPHA appears on AIR within 60 seconds (when online)
   - Vector similarity search returns actual results
   - MCP server tools callable and functional

**Phase 4 Status:** MCP servers deployed, ready for IDE integration

---

## Timeline Summary

- **Phase 1** (ALPHA Primary): 60 minutes
- **Phase 2** (BETA Replica): 45 minutes  
- **Phase 3** (AIR Client): 30 minutes
- **Phase 4** (MCP Servers): 60 minutes
- **Total Implementation**: ~3 hours 15 minutes

---

## Next Steps

1. Complete all verification tests from each phase
2. Document actual test results and measurements
3. Integrate MCP servers with IDE configuration
4. Migrate existing knowledge from SQLite
5. Perform failover testing
6. Document operational procedures

---

**Document Status:** Implementation plan complete, ready for execution

**Created:** October 6, 2025 00:10:02  
**Author:** arthurdell  
**System:** ALPHA.local
